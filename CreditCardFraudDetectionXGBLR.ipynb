{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "it-s9PhssQyA"
   },
   "source": [
    "### __Importing all the required libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PnmPEP93HoNq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from imblearn.over_sampling import ADASYN \n",
    "from collections import Counter\n",
    "import seaborn as sn\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEt_6qgYskp2"
   },
   "source": [
    "### __Importing dataset__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GRGJs1n7wfIr"
   },
   "source": [
    "**--->We can see that features are V1, V2,V3 and so on. These features are obtained by doing PCA on the dataset. The dataset we have is already applied with PCA maybe because of sensitive data of the users is present there. \n",
    "'Time' and 'Amount' are the features which are not transformed using PCA i.e. they are in their original state.\n",
    "Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. Feature 'Class' is the target variable with value 1 in case of fraud and 0 otherwise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "RK9HrmQTH4pb",
    "outputId": "3eb667d4-7880-4dea-c706-6280050b5ecf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv') #'/content/drive/My Drive/Colab Notebooks/Datasets/creditcard.csv'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE90d6g4vV02"
   },
   "source": [
    "### __Checking the information of the dataset i.e. number of columns, number of rows in each column, missing values can be spotted if all the columns don't have same number of records and so on.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "colab_type": "code",
    "id": "hmundnY1H4sd",
    "outputId": "8a4439b2-5d2f-46db-aa8e-7cba1cd9d894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_sS50-ZCshu"
   },
   "source": [
    "### Checking Null values if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "colab_type": "code",
    "id": "lyluENi3CHSx",
    "outputId": "30017a6c-54a3-4917-bfc2-9870a1e598d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4cxfTbrYCyLg"
   },
   "source": [
    "### Displaying total number of fraud and non fraud transactions which is represented in column \"Class\" as 0 and 1, where, 0 = Non fraud transactions and 1 = Fraud transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "4pMP4yXGH4ws",
    "outputId": "cf7c3039-053e-4670-9817-6921e23b96e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal transactions count:  284315\n",
      "Fraudulent transactions count:  492\n"
     ]
    }
   ],
   "source": [
    "print('Normal transactions count: ', df['Class'].value_counts().values[0])\n",
    "print('Fraudulent transactions count: ', df['Class'].value_counts().values[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will plot histogram to see the distribution of our fraud and non fraud transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df['Class']\n",
    "num_bins = 10\n",
    "n, bins, patches = plt.hist(x, num_bins, facecolor='red', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This graph shows that our data is highly imbalanced as we can see that non fraud transactions are in lakhs whereas frauds are just in hundreds. So, we need to balance this data for training our model to make a good model. We will do it by applying over-sampling technique ahead.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "skHCeTr4DRxv"
   },
   "source": [
    "### Dropping the predictor column i.e. \"Class\" and placing it seperately in y as it is predictor for fraud and non fraud transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rTiTHQXOH403"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1] #Dropping \"Class\" column using implicit location index of the column\n",
    "\n",
    "y = df['Class'] # Adding \"Class\" column to the y variable and storing it there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NkXprXLUEhdo"
   },
   "source": [
    "### Scailing the data to have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LAWnGQR6H4-K"
   },
   "outputs": [],
   "source": [
    "# scale using standard scalar in sklearn package\n",
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJDrBo1gFCTE"
   },
   "source": [
    "### Splitting the data in train and test to train the model on training data and test its performance on tesr data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOkaPliSH5Cv"
   },
   "outputs": [],
   "source": [
    "# Partition data into train and test sets by specifying test size and random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.30, random_state=95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cBkPQU--FyLO"
   },
   "source": [
    "__We noticed that Normal transactions count is 284315 and Fraudulent transactions count is 492. This is highly imbalanced data as non fraud transaction data is huge whereas, fraud transaction data is very less for trainind. So,it needs to be balanced to train our model to give better prediction on unseen or test data.__\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We will use ADASYN oversampling method, to balance our dataset, from imbalanced-learn package to resample the dataset.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ADASYN (ADAptive SYNthetic) is an oversampling technique that adaptively generates minority data samples according to their distributions using K nearest neighbor.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "xz7Q0J2FH5HP",
    "outputId": "5f7cbe2f-77de-42b9-ec97-3c671c39db61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 199018, 1: 346})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 199018, 1: 199008})\n"
     ]
    }
   ],
   "source": [
    "# Applying the ADASYN over-sampling\n",
    "ada = ADASYN(random_state=42)\n",
    "print('Original dataset shape {}'.format(Counter(y_train))) #printing original dataset's fraud and non fraud transactions\n",
    "X_res, y_res = ada.fit_sample(X_train, y_train)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res))) #printing resampled dataset's fraud and non fraud transactions which are almost equal now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-1cf6c086b6fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_res\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnum_bins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_bins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfacecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_res' is not defined"
     ]
    }
   ],
   "source": [
    "x = y_res\n",
    "num_bins = 10\n",
    "n, bins, patches = plt.hist(x, num_bins, facecolor='red', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kXZByRLHIOWx"
   },
   "source": [
    "# Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "uzmDTGueH5MD",
    "outputId": "88c866f1-ae1b-44c5-d3f8-8f9b1aeed7b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=1,\n",
       "              min_child_weight=1, missing=None, n_estimators=1, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = X_res, y_res  # this assigns resampled/balanced dataset to model for training\n",
    "\n",
    "# Train LogisticRegression Model\n",
    "LGR_Classifier = LogisticRegression(penalty='none', tol=0.0001, C=1, intercept_scaling=1.0) # creating our model with hyperparameters\n",
    "LGR_Classifier.fit(X_train, y_train);\n",
    "\n",
    "# Train Random Forest Model\n",
    "#RDF_Classifier = RandomForestClassifier(random_state=0)\n",
    "#RDF_Classifier.fit(X_train, y_train);\n",
    "\n",
    "# Train Bernoulli Naive Baye Model\n",
    "#BNB_Classifier = BernoulliNB()\n",
    "#BNB_Classifier.fit(X_train, y_train);\n",
    "\n",
    "# Train XGBoost Model\n",
    "XGB_clf = xgb.XGBClassifier(n_estimators=1,learning_rate=0.01,max_depth=1) # creating our model with hyperparameters\n",
    "XGB_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HY9bUqfTI9WR"
   },
   "source": [
    "# Evaluating trained models on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "XCM-t8ptH5Y4",
    "outputId": "aaf22b49-f87c-4814-b3da-d2ad9cb523b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================== Model Evaluation Results ========================\n",
      "\n",
      "==================== LogisticRegression ===================\n",
      "\n",
      "Cross Validation Mean Score:  86.2%\n",
      "\n",
      "Model Accuracy:  87.9%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[181801  17217]\n",
      " [ 30906 168102]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88    199018\n",
      "           1       0.91      0.84      0.87    199008\n",
      "\n",
      "    accuracy                           0.88    398026\n",
      "   macro avg       0.88      0.88      0.88    398026\n",
      "weighted avg       0.88      0.88      0.88    398026\n",
      "\n",
      "\n",
      "==================== XGBoost ===================\n",
      "\n",
      "Cross Validation Mean Score:  74.7%\n",
      "\n",
      "Model Accuracy:  78.2%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[172302  26716]\n",
      " [ 59895 139113]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.87      0.80    199018\n",
      "           1       0.84      0.70      0.76    199008\n",
      "\n",
      "    accuracy                           0.78    398026\n",
      "   macro avg       0.79      0.78      0.78    398026\n",
      "weighted avg       0.79      0.78      0.78    398026\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "modlist = [('LogisticRegression', LGR_Classifier),('XGBoost',XGB_clf)]  \n",
    "# List of our models to iterate in the loop for printing results one after other\n",
    "\n",
    "models = [j for j in modlist] \n",
    "\n",
    "print()\n",
    "print('========================== Model Evaluation Results ========================' \"\\n\")  \n",
    "\n",
    "\n",
    "# Printing metrics to analyse the performance of the model\n",
    "for i, v in models:\n",
    "    scores = cross_val_score(v, X_train, y_train, cv=10)\n",
    "    accuracy = metrics.accuracy_score(y_train, v.predict(X_train))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_train, v.predict(X_train))\n",
    "    classification = metrics.classification_report(y_train, v.predict(X_train))\n",
    "    print('==================== {} ==================='.format(i))\n",
    "    print()\n",
    "    print (\"Cross Validation Mean Score: \", '{}%'.format(np.round(scores.mean(), 3) * 100))  \n",
    "    print() \n",
    "    print (\"Model Accuracy: \", '{}%'.format(np.round(accuracy, 3) * 100)) \n",
    "    print()\n",
    "    print(\"Confusion Matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification Report:\" \"\\n\", classification) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jVmtt5mMNaOC"
   },
   "source": [
    "__---> In Logistic Regression model, we can notice that model accuracy on training data is 87.9%. Precision and recall also looks good. f1-score which is calculated using precision and recall is 88% and 87% which is good.__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__--->In XGBoost Classifier model, we can notice that model accuracy on training data is 78.2%. Precision and recall also looks fine. f1-score which is calculated using precision and recall is 80% and 76% which is fine but not that good__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t3PFy3lPJpDJ"
   },
   "source": [
    "# Testing trained model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 710
    },
    "colab_type": "code",
    "id": "R0oQL_KVQSUw",
    "outputId": "2c134605-c441-4818-e4b7-a027871c8988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================== Model Test Results ========================\n",
      "\n",
      "==================== LogisticRegression ===================\n",
      "Model Accuracy:  91.5%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[78003  7294]\n",
      " [    5   141]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.96     85297\n",
      "           1       0.02      0.97      0.04       146\n",
      "\n",
      "    accuracy                           0.91     85443\n",
      "   macro avg       0.51      0.94      0.50     85443\n",
      "weighted avg       1.00      0.91      0.95     85443\n",
      "\n",
      "\n",
      "==================== XGBoost ===================\n",
      "Model Accuracy:  86.4%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[73692 11605]\n",
      " [    9   137]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93     85297\n",
      "           1       0.01      0.94      0.02       146\n",
      "\n",
      "    accuracy                           0.86     85443\n",
      "   macro avg       0.51      0.90      0.48     85443\n",
      "weighted avg       1.00      0.86      0.93     85443\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test models\n",
    "classdict = {'normal':0, 'fraudulent':1}\n",
    "print()\n",
    "print('========================== Model Test Results ========================' \"\\n\")   \n",
    "\n",
    "\n",
    "# Printing metrics to analyse the performance of the model\n",
    "for i, v in models:\n",
    "    accuracy = metrics.accuracy_score(y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, v.predict(X_test))\n",
    "    classification = metrics.classification_report(y_test, v.predict(X_test))   \n",
    "    print('==================== {} ==================='.format(i))\n",
    "    print (\"Model Accuracy: \",  '{}%'.format(np.round(accuracy, 3) * 100))\n",
    "    print()\n",
    "    print(\"Confusion Matrix:\" \"\\n\", confusion_matrix)\n",
    "    print() \n",
    "    print(\"Classification Report:\" \"\\n\", classification) \n",
    "    print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WiZjMkyQXqRk"
   },
   "source": [
    "__--->In Logistic Regression model, we can notice that model accuracy on test data is 91.5%. Precision and recall also looks good. f1-score which is calculated using precision and recall is low for fraud transactions as test data is not resampled or balanced data.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model is performing good in predicting as it has 91.5% accuracy along with other metrics which are showing good results.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__--->In XGBoost Classifier model, we can notice that model accuracy on test data is 86.4%. Precision and recall also looks good. f1-score which is calculated using precision and recall is low for fraud transactions as test data is not resampled or balanced data.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model is performing good in predicting as it has 86.4% accuracy along with other metrics which are showing good results.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2sZSFdrKNPW"
   },
   "source": [
    "# HyperParameter Tuning using GridSearchCV for XGBoost Classifier algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "3_QUj7lEMkwt",
    "outputId": "fb9bd64f-8fcd-4ee9-98d1-cc17d035f197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========Best Estimator===========\n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
      "              min_child_weight=1, missing=None, n_estimators=20, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "===========Best Score===========\n",
      "\n",
      "0.9267309146879453\n",
      "===========Best Parameters===========\n",
      "\n",
      "{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "#grid search for XGBoost\n",
    "\n",
    "# input hyperparameters for tuning\n",
    "param_distXGB = {\n",
    "    \"n_estimators\" : [5,10,20], \n",
    "    \"max_depth\" : [5,10],\n",
    "    \"learning_rate\":[0.01] \n",
    "}\n",
    "\n",
    "\n",
    "#importing GridSearchCV and setting parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gridXGB = GridSearchCV(XGB_clf, param_grid=param_distXGB, n_jobs=-1)\n",
    "\n",
    "\n",
    "#Training model with the specified hyperparameters and printing best estimator, score and parameters\n",
    "gridXGB.fit(X_train,y_train)\n",
    "print(\"===========Best Estimator===========\"\"\\n\")\n",
    "print(gridXGB.best_estimator_)\n",
    "print(\"===========Best Score===========\"\"\\n\")\n",
    "print(gridXGB.best_score_)\n",
    "print(\"===========Best Parameters===========\"\"\\n\")\n",
    "print(gridXGB.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "caTiO4lTLGWC"
   },
   "source": [
    "# HyperParameter Tuning using GridSearchCV for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "qJB1G246Mk6e",
    "outputId": "cc51d2af-9240-4e56-ad1c-7352552f9315"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========Best Estimator===========\n",
      "\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1.0, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=1,\n",
      "                   warm_start=False)\n",
      "===========Best Score===========\n",
      "\n",
      "0.8626722418791261\n",
      "===========Best Parameters===========\n",
      "\n",
      "{'intercept_scaling': 1.0, 'penalty': 'l2', 'verbose': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s finished\n"
     ]
    }
   ],
   "source": [
    "#grid search for Logistic regression\n",
    "\n",
    "# input hyperparameters for tuning\n",
    "param_distLR = {\n",
    "    'penalty':['l2','none'],  \n",
    "    'verbose':[1,2,5,10],\n",
    "    'intercept_scaling':[1.0,2.0,3.0]\n",
    "}\n",
    "\n",
    "#importing GridSearchCV and setting parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gridLR = GridSearchCV(LGR_Classifier, param_grid=param_distLR, n_jobs=-1)\n",
    "\n",
    "#Training model with the specified hyperparameters and printing best estimator, score and parameters\n",
    "gridLR.fit(X_train,y_train)\n",
    "\n",
    "print(\"===========Best Estimator===========\"\"\\n\")\n",
    "print(gridLR.best_estimator_)\n",
    "print(\"===========Best Score===========\"\"\\n\")\n",
    "print(gridLR.best_score_)\n",
    "print(\"===========Best Parameters===========\"\"\\n\")\n",
    "print(gridLR.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4DFkiJ6bLmYk"
   },
   "source": [
    "# Training new models using best parameters obtained through GridSearchCV for XGBoost and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "c6V-bBiMOqO2",
    "outputId": "b2dc2248-e034-46c8-8627-61423088e0d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=1, missing=None, n_estimators=20, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = X_res, y_res \n",
    "\n",
    "# Train LogisticRegression Model\n",
    "LGR_Classifier1 = LogisticRegression(penalty='l2',intercept_scaling=1.0, verbose=1)\n",
    "LGR_Classifier1.fit(X_train, y_train);\n",
    "\n",
    "\n",
    "# Train XGBoost Model\n",
    "XGB_clf1 = xgb.XGBClassifier(n_estimators=20,learning_rate=0.01,max_depth=10) #n_estimators=20,learning_rate=0.01,max_depth=10\n",
    "XGB_clf1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGUyWoCgaCx2"
   },
   "source": [
    "__Above training models are given hyper parameters as input which we got from Best Parameters from GridSearchCV__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I10iNkGSL9Xt"
   },
   "source": [
    "# Evaluating trained models on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pukguRaZOqkK",
    "outputId": "986271a2-da38-42db-bb87-a65436f4d311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================== Model Evaluation Results ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== LogisticRegression ===================\n",
      "\n",
      "Cross Validation Mean Score:  86.2%\n",
      "\n",
      "Model Accuracy:  87.9%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[181788  17230]\n",
      " [ 30918 168090]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88    199018\n",
      "           1       0.91      0.84      0.87    199008\n",
      "\n",
      "    accuracy                           0.88    398026\n",
      "   macro avg       0.88      0.88      0.88    398026\n",
      "weighted avg       0.88      0.88      0.88    398026\n",
      "\n",
      "\n",
      "==================== XGBoost ===================\n",
      "\n",
      "Cross Validation Mean Score:  92.80000000000001%\n",
      "\n",
      "Model Accuracy:  98.6%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[193912   5106]\n",
      " [   506 198502]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99    199018\n",
      "           1       0.97      1.00      0.99    199008\n",
      "\n",
      "    accuracy                           0.99    398026\n",
      "   macro avg       0.99      0.99      0.99    398026\n",
      "weighted avg       0.99      0.99      0.99    398026\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "modlist1 = [('LogisticRegression', LGR_Classifier1),('XGBoost',XGB_clf1)] \n",
    "# List of our models to iterate in the loop for printing results one after other\n",
    "\n",
    "models1 = [j for j in modlist1]\n",
    "\n",
    "print()\n",
    "print('========================== Model Evaluation Results ========================' \"\\n\")  \n",
    "\n",
    "# Printing metrics to analyse the performance of the model\n",
    "for i, v in models1:\n",
    "    scores = cross_val_score(v, X_train, y_train, cv=10)\n",
    "    accuracy = metrics.accuracy_score(y_train, v.predict(X_train))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_train, v.predict(X_train))\n",
    "    classification = metrics.classification_report(y_train, v.predict(X_train))\n",
    "    print('==================== {} ==================='.format(i))\n",
    "    print()\n",
    "    print (\"Cross Validation Mean Score: \", '{}%'.format(np.round(scores.mean(), 3) * 100))  \n",
    "    print() \n",
    "    print (\"Model Accuracy: \", '{}%'.format(np.round(accuracy, 3) * 100)) \n",
    "    print()\n",
    "    print(\"Confusion Matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification Report:\" \"\\n\", classification) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gxCLJbONa5y3"
   },
   "source": [
    "__---> In Logistic Regression model, we can notice that model accuracy on training data is 87.9% which is same as before tuning the paramaters using GridSearchCV. Precision, Recall and f1-score is also same.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__So, we see that there is not much change in model even after tuning with best parameters we got from GridSearchCV.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__--->In XGBoost Classifier model, we can notice that model accuracy on training data is 98.6%. Precision and recall are very good. f1-score which is calculated using precision and recall is 99% and 99% is also very good.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 710
    },
    "colab_type": "code",
    "id": "CHe46GXsH5cL",
    "outputId": "882c496b-6b70-4b10-cc1a-36355043ff55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================== Model Test Results ========================\n",
      "\n",
      "==================== LogisticRegression ===================\n",
      "Model Accuracy:  91.4%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[77995  7302]\n",
      " [    5   141]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.96     85297\n",
      "           1       0.02      0.97      0.04       146\n",
      "\n",
      "    accuracy                           0.91     85443\n",
      "   macro avg       0.51      0.94      0.50     85443\n",
      "weighted avg       1.00      0.91      0.95     85443\n",
      "\n",
      "\n",
      "==================== XGBoost ===================\n",
      "Model Accuracy:  97.3%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[83020  2277]\n",
      " [   20   126]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     85297\n",
      "           1       0.05      0.86      0.10       146\n",
      "\n",
      "    accuracy                           0.97     85443\n",
      "   macro avg       0.53      0.92      0.54     85443\n",
      "weighted avg       1.00      0.97      0.98     85443\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test models\n",
    "classdict = {'normal':0, 'fraudulent':1}\n",
    "print()\n",
    "print('========================== Model Test Results ========================' \"\\n\")   \n",
    "\n",
    "# Printing metrics to analyse the performance of the model\n",
    "for i, v in models1:\n",
    "    accuracy = metrics.accuracy_score(y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, v.predict(X_test))\n",
    "    classification = metrics.classification_report(y_test, v.predict(X_test))   \n",
    "    print('==================== {} ==================='.format(i))\n",
    "    print (\"Model Accuracy: \",  '{}%'.format(np.round(accuracy, 3) * 100))\n",
    "    print()\n",
    "    print(\"Confusion Matrix:\" \"\\n\", confusion_matrix)\n",
    "    print() \n",
    "    print(\"Classification Report:\" \"\\n\", classification) \n",
    "    print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfY5DmHbcB2q"
   },
   "source": [
    "__--->In Logistic Regression model, we can notice that model accuracy on test data is 91.4%. It has dropped by 0.1% and performs same as before.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model is performing good in predicting as it has 91.4% accuracy along with other metrics which are showing good results.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__--->In XGBoost Classifier model, we can notice that model accuracy on test data is 97.3%. Precision and recall are good. f1-score which is calculated using precision and recall is low for fraud transactions as test data is not resampled or balanced data.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model is performing good in predicting as it has 97.3% accuracy along with other metrics which are showing good results.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KfRmcW1ic0WU"
   },
   "source": [
    "# ---------->CONCLUSION<------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYkZNHz_dEAw"
   },
   "source": [
    "__Logistic Regression model performs very good but is performing same after HyperParameter tuning.__\n",
    "__XGBoost Classifier model performs good on test data and performs best after HyperParemeter tuning.__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFHXUBvmeFod"
   },
   "source": [
    "__So, we can say that XGBoost Classifier model out performs with very good numbers when tuning properly. Also, Logistic Regression model performs very good but needs to be tune properly and train alot for increasing its score.__"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "xgbUpdated2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
